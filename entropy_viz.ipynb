{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/workspace/viv41siv/anaconda3/envs/unc/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# from torchcam.methods import LayerCAM, SmoothGradCAMpp\n",
    "# from torchcam.utils import overlay_mask\n",
    "\n",
    "import clip\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "\n",
    "from models.resnet import CustomResNet\n",
    "from models.projector import ProjectionHead\n",
    "from domainnet_data import DomainNetDataset, get_domainnet_loaders, get_data_from_saved_files\n",
    "from utils_proj import SimpleDINOLoss, compute_accuracy, compute_similarities, plot_grad_flow, plot_confusion_matrix\n",
    "from prompts.FLM import generate_label_mapping_by_frequency, label_mapping_base\n",
    "from models.resnet import CustomClassifier, CustomResNet\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_level_entropies(entropy_, label_list, num_classes):\n",
    "    class_entropies = {}\n",
    "    for class_idx in range(num_classes):\n",
    "        class_mask = (label_list == class_idx)\n",
    "        class_entropies[class_idx] += torch.sum(entropy_[class_mask])\n",
    "    class_entropies /= len(entropy_)\n",
    "    return class_entropies\n",
    "\n",
    "def entropy(prob):\n",
    "    \"\"\"\n",
    "    Compute the entropy of the mean of the predictive distribution\n",
    "    obtained from Monte Carlo sampling during prediction phase.\n",
    "    \"\"\"\n",
    "    return -1 * np.sum(prob * np.log(prob + 1e-15), axis=-1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_entropy(val_loader,classifier,clip_model,clip_text_encodings,projector,PROJ_CLIP, device):\n",
    "    all_clip_embeddings = []\n",
    "\n",
    "    all_classifier_embeddings = []\n",
    "    all_proj_embeddings = []\n",
    "    all_clip_text_embeddings = []\n",
    "    l = []\n",
    "\n",
    "    classifier_prob_list, proj_prob_list, CLIP_prob_list = [], [], []\n",
    "    clip_text_encodings=clip_text_encodings.to(device)\n",
    "\n",
    "    for i,(images_batch, labels, images_clip_batch) in enumerate(val_loader):\n",
    "        images_batch = images_batch.to(device)\n",
    "        images_clip_batch = images_clip_batch.to(device)    \n",
    "        labels = labels.to(device)\n",
    "        l.append(labels.cpu())\n",
    "        \n",
    "        classifier_logits, classifier_embeddings = classifier(images_batch, return_features=True) # (batch_size, embedding_dim)\n",
    "\n",
    "        clip_image_embeddings = clip_model.encode_image(images_clip_batch) # (batch_size, embedding_dim)\n",
    "        \n",
    "        clip_image_embeddings = clip_image_embeddings.type_as(classifier_embeddings)\n",
    "\n",
    "        if PROJ_CLIP: # this is PLUMBER\n",
    "            proj_embeddings = projector(clip_image_embeddings) # (batch_size, projection_dim)\n",
    "        else: # this is LIMBER\n",
    "            proj_embeddings = projector(classifier_embeddings) # (batch_size, projection_dim)\n",
    "\n",
    "        normalized_clip_embeddings = F.normalize(clip_image_embeddings, dim=-1)\n",
    "        normalized_proj_embeddings = F.normalize(proj_embeddings, dim=-1)\n",
    "        normalized_text_encodings = F.normalize(clip_text_encodings, dim=-1)\n",
    "        normalized_text_encodings = normalized_text_encodings.type_as(normalized_proj_embeddings)\n",
    "\n",
    "        # T100 is the logits scale from CLIP\n",
    "        projection_logits = 100*normalized_proj_embeddings @ normalized_text_encodings.t() # (batch_size, num_classes)\n",
    "        CLIP_logits = 100*normalized_clip_embeddings @ normalized_text_encodings.t() # (batch_size, num_classes)\n",
    "\n",
    "        probs_from_classifier = F.softmax(classifier_logits, dim=-1)\n",
    "        probs_from_proj = F.softmax(projection_logits, dim=-1)\n",
    "        probs_from_CLIP = F.softmax(CLIP_logits, dim=-1)\n",
    "\n",
    "        classifier_prob_list.append(probs_from_classifier)\n",
    "        proj_prob_list.append(probs_from_proj)\n",
    "        CLIP_prob_list.append(probs_from_CLIP)\n",
    "        \n",
    "\n",
    "    classifier_prob_list = torch.cat(classifier_prob_list, dim=0)\n",
    "    proj_prob_list = torch.cat(proj_prob_list, dim=0)\n",
    "    CLIP_prob_list = torch.cat(CLIP_prob_list, dim=0)\n",
    "    \n",
    "    return classifier_prob_list, proj_prob_list, CLIP_prob_list, l\n",
    "\n",
    "def build_classifier(classifier_name, num_classes, pretrained=False, checkpoint_path=None):\n",
    "\n",
    "    if classifier_name in ['vit_b_16', 'swin_b']:\n",
    "        classifier = CustomClassifier(classifier_name, use_pretrained=pretrained)\n",
    "    elif classifier_name in ['resnet18', 'resnet50']:\n",
    "        classifier = CustomResNet(classifier_name, num_classes=num_classes, use_pretrained=pretrained)\n",
    "\n",
    "    if checkpoint_path:\n",
    "        classifier.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])\n",
    "\n",
    "    train_transform = classifier.train_transform\n",
    "    test_transform = classifier.test_transform\n",
    "\n",
    "    return classifier, train_transform, test_transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"/usr/workspace/viv41siv/CVPR2024/failure-detection/ood_detect/data/domainnet_v1.0\"\n",
    "prompt_embeddings_pth = \"/usr/workspace/KDML/DomainNet/CLIP_ViT-B-32_text_encodings.pt\"\n",
    "classifier_name= \"resnet50\"\n",
    "num_classes = 345\n",
    "\n",
    "projector_weights_path= '/usr/workspace/KDML/ood_detect/checkpoints/painting_test_projector/best_projector_weights.pth'\n",
    "#projector_weights_path = \"/usr/workspace/KDML/ood_detect/resnet50_domainnet_real/plumber/resnet50domain_{sketch}_lr_0.1_is_mlp_False/projector_weights_final.pth\"\n",
    "checkpoint_path = f\"{data_dir}/best_checkpoint.pth\"\n",
    "PROJ_CLIP = True\n",
    "dataset_name=\"domainnet\"\n",
    "domain_name=\"clipart\"\n",
    "domainnet_domains_projector= {\"real\":'/usr/workspace/KDML/ood_detect/checkpoints/painting_test_projector/best_projector_weights.pth',\\\n",
    "                              \"sketch\": \"/usr/workspace/KDML/ood_detect/resnet50_domainnet_real/plumber/resnet50domain_{sketch}_lr_0.1_is_mlp_False/projector_weights_final.pth\",\\\n",
    "                             \"painting\": \"/usr/workspace/KDML/ood_detect/checkpoints/painting_test_projector/best_projector_weights.pth\",\\\n",
    "                             \"clipart\": \"/usr/workspace/KDML/ood_detect/checkpoints/clipart_test_projector/best_projector_weights.pth\"\n",
    "}      \n",
    "# Load class names from a text file\n",
    "with open(os.path.join(data_dir, 'class_names.txt'), 'r') as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "####################\n",
    "\n",
    "    \n",
    "\n",
    "text_encodings = torch.load(prompt_embeddings_pth)\n",
    "\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model.eval()\n",
    "\n",
    "classifier, train_transform, test_transform = build_classifier(classifier_name, num_classes, pretrained=False, checkpoint_path=checkpoint_path)\n",
    "classifier= classifier.to(device)\n",
    "classifier.eval()\n",
    "\n",
    "classifier_entropy={}\n",
    "proj_entropy={}\n",
    "CLIP_entropy={}\n",
    "for domain_name in domainnet_domains_projector.keys():\n",
    "\n",
    "    projector = ProjectionHead(input_dim=512, output_dim=512).to(device)\n",
    "    projector.load_state_dict(torch.load(domainnet_domains_projector[domain_name])['projector'])\n",
    "    projector.eval()\n",
    "\n",
    "\n",
    "    train_dataset, val_dataset, class_names = get_dataset(dataset_name, domain_name,train_transform, test_transform, \n",
    "                                                                data_dir=data_dir, clip_transform=preprocess)\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=True)\n",
    "    classifier_prob_list, proj_prob_list, CLIP_prob_list, label_list = get_entropy(val_loader,classifier,clip_model,text_encodings,projector,device)\n",
    "    \n",
    "    entropy_classifer = entropy(classifier_prob_list.cpu().data.numpy())\n",
    "    entropy_proj = entropy(proj_prob_list.cpu().data.numpy())\n",
    "    entropy_CLIP = entropy(CLIP_prob_list.cpu().data.numpy())\n",
    "\n",
    "    classifier_entropy[domain_name] = class_level_entropies(entropy_classifer, label_list)\n",
    "    proj_entropy[domain_name] = class_level_entropies(entropy_proj, label_list)\n",
    "    CLIP_entropy[domain_name] = class_level_entropies(entropy_CLIP, label_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4x4 grid of subplots\n",
    "fig, axs = plt.subplots(4, 3, figsize=(12, 12))\n",
    "\n",
    "# Populate each subplot with a stem plot\n",
    "for i, domain_name in enumerate(domainnet_domains_projector.keys()):\n",
    "    axs[i, 0].stem(range(345), classifier_entropy[domain_name], basefmt='b', linefmt='r-', markerfmt='ro')\n",
    "    axs[i, 1].stem(range(345), proj_entropy[domain_name], basefmt='b', linefmt='r-', markerfmt='ro')\n",
    "    axs[i, 2].stem(range(345), CLIP_entropy[domain_name], basefmt='b', linefmt='r-', markerfmt='ro')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47079ad2e46369d736a8440b70f51c237e75ba9076dbb496e5c14257ec37b23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
