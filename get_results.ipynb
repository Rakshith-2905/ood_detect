{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.8296083807945251, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.09329232573509216, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.8532018065452576, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.8319001197814941, 'Model Type': 'plumber_img_prompt'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.7491099834442139, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.1889888346195221, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.8003780841827393, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.750499963760376, 'Model Type': 'plumber_img_text_proj_img_prompt_cls_LP'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.8979430794715881, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.286221981048584, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.9054774641990662, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.9002999663352966, 'Model Type': 'plumber_img_proj'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.7053006291389465, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.01264200173318386, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.8194021582603455, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.7062000036239624, 'Model Type': 'plumber_img_prompt_cls_LP'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.33870649337768555, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.050310008227825165, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.38435307145118713, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.3369000256061554, 'Model Type': 'plumber_text_proj_img_prompt'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.9119857549667358, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.23129484057426453, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.917681872844696, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.9138000011444092, 'Model Type': 'plumber_img_proj_cls_LP'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.6929391026496887, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.3551533818244934, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.7393441796302795, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.6944000720977783, 'Model Type': 'plumber_img_text_proj'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.37054985761642456, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.026566585525870323, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.42036834359169006, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.368399977684021, 'Model Type': 'plumber_text_proj_img_prompt_cls_LP'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.3916139304637909, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.08639843761920929, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.4862724542617798, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.3903999924659729, 'Model Type': 'plumber_img_proj_img_prompt'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.8217958807945251, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.41152501106262207, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.8301588296890259, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.8247000575065613, 'Model Type': 'plumber_img_text_proj_cls_LP'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.8041930794715881, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.131010964512825, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.8114829063415527, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.8047999143600464, 'Model Type': 'plumber_img_proj_img_prompt_cls_LP'}\n",
      "{'base_model_acc': 0.7276503443717957, 'plumber_acc': 0.3150712251663208, 'base_model_ece': 0.20774361491203308, 'plumber_ece': 0.09687076508998871, 'base_model_precision': 0.7343288064002991, 'plumber_precision': 0.559482216835022, 'base_model_recall': 0.728100061416626, 'plumber_recall': 0.3172000050544739, 'Model Type': 'plumber_img_text_proj_img_prompt'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the base folders\n",
    "model_types = [\n",
    "    \"plumber_img_prompt\", \"plumber_img_text_proj_img_prompt_cls_LP\",\n",
    "    \"plumber_img_proj\", \"plumber_img_prompt_cls_LP\", \n",
    "    \"plumber_text_proj_img_prompt\", \"plumber_img_proj_cls_LP\", \n",
    "    \"plumber_img_text_proj\", \"plumber_text_proj_img_prompt_cls_LP\", \n",
    "    \"plumber_img_proj_img_prompt\", \"plumber_img_text_proj_cls_LP\", \n",
    "    \"plumber_img_proj_img_prompt_cls_LP\", \"plumber_img_text_proj_img_prompt\"\n",
    "]\n",
    "corruption_folders = [\n",
    "    \"brightness\", \"contrast\", \"defocus_blur\", \"elastic_transform\", \"fog\",\n",
    "    \"frost\", \"gaussian_blur\", \"gaussian_noise\", \"glass_blur\", \"impulse_noise\",\n",
    "    \"jpeg_compression\", \"motion_blur\", \"pixelate\", \"saturate\", \"shot_noise\",\n",
    "    \"snow\", \"spatter\", \"speckle_noise\", \"zoom_blur\"\n",
    "]\n",
    "# corruption_folders = [f\"cifar10-c_{folder}_4\" for folder in corruption_folders]\n",
    "\n",
    "# corruption_folders = [\"clipart\", \"infograph\", \"painting\", \"quickdraw\", \"real\", \"sketch\"]\n",
    "# corruption_folders = [f\"{folder}\" for folder in corruption_folders]\n",
    "\n",
    "\n",
    "corruption_folders = [\"\"]\n",
    "\n",
    "dataset = \"cifar10-limited\"\n",
    "save_data_name = \"cifar10-limited\"\n",
    "model_name = \"resnet18\"\n",
    "\n",
    "epoch = 29\n",
    "\n",
    "# Directory where these folders are located\n",
    "base_directory = f\"logs/{dataset}/{model_name}\"  # Replace with the actual path\n",
    "\n",
    "remaining_dir = f\"_clsEpoch_{epoch}_bs_128_lr_0.1_teT_2.0_sT_1.0_imgweight_1.0_txtweight_1.0_is_mlp_False/step_1/logs\"\n",
    "\n",
    "def extract_metrics_from_json(file_path, model_type):\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "data_list = []\n",
    "# Iterate over the base folders and corruption folders\n",
    "for model_type in model_types:\n",
    "    path = os.path.join(base_directory, model_type)\n",
    "    for corruption_folder in corruption_folders:\n",
    "        metrics_file = os.path.join(path, remaining_dir, \"test_task_distillation.json\")\n",
    "        if os.path.exists(metrics_file):\n",
    "            metrics_data = extract_metrics_from_json(metrics_file, model_type)\n",
    "            metrics_data[\"Model Type\"] = model_type\n",
    "            print(metrics_data)\n",
    "            data_list.append(metrics_data)\n",
    "        else:\n",
    "            print(\"Metrics file not found for\", metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Model Type       acc       ece  \\\n",
      "0                                          Task Model  0.727650  0.207744   \n",
      "5                                      Image (Prompt)  0.829608  0.093292   \n",
      "1                                     Image (Project)  0.897943  0.286222   \n",
      "3                            Image (Prompt + Project)  0.391614  0.086398   \n",
      "6                  Image (Prompt) + Text (Cls Prompt)  0.705301  0.012642   \n",
      "11                    Image (Prompt) + Text (Project)  0.338706  0.050310   \n",
      "12           Image (Prompt) + Text (Prompt + Project)  0.370550  0.026567   \n",
      "2                 Image (Project) + Text (Cls Prompt)  0.911986  0.231295   \n",
      "7                    Image (Project) + Text (Project)  0.692939  0.355153   \n",
      "8           Image (Project) + Text (Prompt + Project)  0.821796  0.411525   \n",
      "4        Image (Prompt + Project) + Text (Cls Prompt)  0.804193  0.131011   \n",
      "9           Image (Prompt + Project) + Text (Project)  0.315071  0.096871   \n",
      "10  Image (Prompt + Project) + Text (Prompt + Proj...  0.749110  0.188989   \n",
      "\n",
      "    precision  recall  \n",
      "0    0.734329  0.7281  \n",
      "5    0.853202  0.8319  \n",
      "1    0.905477  0.9003  \n",
      "3    0.486272  0.3904  \n",
      "6    0.819402  0.7062  \n",
      "11   0.384353  0.3369  \n",
      "12   0.420368  0.3684  \n",
      "2    0.917682  0.9138  \n",
      "7    0.739344  0.6944  \n",
      "8    0.830159  0.8247  \n",
      "4    0.811483  0.8048  \n",
      "9    0.559482  0.3172  \n",
      "10   0.800378  0.7505  \n"
     ]
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "new_row_values = {\n",
    "    'acc': df['base_model_acc'][0],\n",
    "    'ece': df['base_model_ece'][0],\n",
    "    'precision': df['base_model_precision'][0],\n",
    "    'recall': df['base_model_recall'][0],\n",
    "    'Model Type': 'Task Model'\n",
    "}\n",
    "\n",
    "# Create a new DataFrame for the new row\n",
    "new_row_df = pd.DataFrame([new_row_values])\n",
    "\n",
    "# Drop the 'base_model_' columns\n",
    "df = df.drop(columns=['base_model_acc', 'base_model_ece', 'base_model_precision', 'base_model_recall'])\n",
    "\n",
    "# Rename 'plumber_' columns\n",
    "df.columns = [col.replace('plumber_', '') for col in df.columns]\n",
    "\n",
    "# Add the new row to the top of the DataFrame\n",
    "df = pd.concat([new_row_df, df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Save the dataframe\n",
    "# df.to_csv(f\"Distill:{save_data_name}-{model_name}.csv\", index=False)\n",
    "\n",
    "\n",
    "# Group by 'Model Type' and 'Feature Type' and calculate mean for specific columns\n",
    "grouped_df = df.groupby(['Model Type']).agg({\n",
    "    'acc': 'mean',\n",
    "    'ece': 'mean',\n",
    "    'precision': 'mean',\n",
    "    'recall': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "model_mapping = {\n",
    "    \"Task Model\": \"Task Model\",\n",
    "    \"Image (Prompt)\": \"plumber_img_prompt\",\n",
    "    \"Image (Project)\": \"plumber_img_proj\",\n",
    "    \"Image (Prompt + Project)\": \"plumber_img_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Cls Prompt)\": \"plumber_img_prompt_cls_LP\",\n",
    "    \"Image (Prompt) + Text (Project)\": \"plumber_text_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Prompt + Project)\": \"plumber_text_proj_img_prompt_cls_LP\",\n",
    "    \"Image (Project) + Text (Cls Prompt)\": \"plumber_img_proj_cls_LP\",\n",
    "    \"Image (Project) + Text (Project)\": \"plumber_img_text_proj\",\n",
    "    \"Image (Project) + Text (Prompt + Project)\": \"plumber_img_text_proj_cls_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Cls Prompt)\": \"plumber_img_proj_img_prompt_cls_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Project)\": \"plumber_img_text_proj_img_prompt\",\n",
    "    \"Image (Prompt + Project) + Text (Prompt + Project)\": \"plumber_img_text_proj_img_prompt_cls_LP\"\n",
    "}\n",
    "# Reverse the dictionary for replacement (value to key)\n",
    "reverse_mapping = {v: k for k, v in model_mapping.items()}\n",
    "\n",
    "# Replace the 'Model Type' in the DataFrame using the reversed mapping\n",
    "grouped_df['Model Type'] = grouped_df['Model Type'].map(reverse_mapping)\n",
    "\n",
    "# Create a custom sort order based on the order of keys in model_mapping\n",
    "sort_order = {k: i for i, k in enumerate(model_mapping.keys())}\n",
    "\n",
    "# Add a temporary sorting column based on the custom order\n",
    "grouped_df['Sort Order'] = grouped_df['Model Type'].map(sort_order)\n",
    "\n",
    "# Sort the DataFrame by this custom order and drop the temporary column\n",
    "grouped_df = grouped_df.sort_values(by='Sort Order').drop('Sort Order', axis=1)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(grouped_df)\n",
    "grouped_df.to_csv(f\"Distill:{save_data_name}-{model_name}-grouped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metrics_from_json(file_path, model_type):\n",
    "    corruption_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the JSON string to a dictionary\n",
    "            data = json.loads(line.strip())\n",
    "            data[\"Model Type\"] = model_type\n",
    "            corruption_data.append(data)\n",
    "\n",
    "    return corruption_data\n",
    "\n",
    "data_list = []\n",
    "# Iterate over the base folders and corruption folders\n",
    "for model_type in model_types:\n",
    "    path = os.path.join(base_directory, model_type)\n",
    "    metrics_file = os.path.join(path, remaining_dir, \"test_task_distillation_corruption.json\")\n",
    "    if os.path.exists(metrics_file):\n",
    "        metrics_data = extract_metrics_from_json(metrics_file, model_type)\n",
    "        data_list.extend(metrics_data)\n",
    "    else:\n",
    "        print(\"Metrics file not found for\", metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Model Type       acc       ece  \\\n",
      "0                                          Task Model  0.589774  0.321821   \n",
      "5                                      Image (Prompt)   0.61993  0.063893   \n",
      "1                                     Image (Project)  0.644976  0.214391   \n",
      "3                            Image (Prompt + Project)  0.303881  0.097341   \n",
      "6                  Image (Prompt) + Text (Cls Prompt)  0.492625  0.151605   \n",
      "11                    Image (Prompt) + Text (Project)  0.255809  0.127105   \n",
      "12           Image (Prompt) + Text (Prompt + Project)  0.278455  0.082587   \n",
      "2                 Image (Project) + Text (Cls Prompt)  0.684049  0.197514   \n",
      "7                    Image (Project) + Text (Project)  0.440711  0.181117   \n",
      "8           Image (Project) + Text (Prompt + Project)  0.559944   0.25718   \n",
      "4        Image (Prompt + Project) + Text (Cls Prompt)  0.599444  0.092466   \n",
      "9           Image (Prompt + Project) + Text (Project)  0.239403  0.055816   \n",
      "10  Image (Prompt + Project) + Text (Prompt + Proj...  0.509103  0.123046   \n",
      "\n",
      "   precision    recall  \n",
      "0   0.657036  0.588458  \n",
      "5   0.739583  0.621458  \n",
      "1   0.744647  0.646747  \n",
      "3   0.424873  0.303489  \n",
      "6   0.740096  0.493979  \n",
      "11  0.311299  0.254474  \n",
      "12  0.323615  0.277816  \n",
      "2   0.767274  0.685411  \n",
      "7    0.55156  0.441411  \n",
      "8   0.681859  0.561647  \n",
      "4   0.688943  0.600411  \n",
      "9    0.40495  0.240574  \n",
      "10  0.684893  0.510679  \n"
     ]
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "df = pd.DataFrame(data_list)\n",
    "# Get new row values for each of the corruption types in the dataframe\n",
    "available_corruptions = df['corruption'].unique()\n",
    "new_row_values = {}\n",
    "\n",
    "# I want this row to have model type, corruption type, acc, ece, precision and recall values from the base model\n",
    "for corruption in available_corruptions:\n",
    "    # Get the row for the base model and the current corruption type\n",
    "    base_model_row = df[df['corruption'] == corruption]\n",
    "    # Get the accuracy, ece, precision and recall values\n",
    "    acc = base_model_row['base_model_acc'].values[0]\n",
    "    ece = base_model_row['base_model_ece'].values[0]\n",
    "    precision = base_model_row['base_model_precision'].values[0]\n",
    "    recall = base_model_row['base_model_recall'].values[0]\n",
    "    severity = base_model_row['severity'].values[0]\n",
    "    # Add the values to the dictionary\n",
    "    new_row_values[corruption] = {\n",
    "        'Model Type': 'Task Model',\n",
    "        'corruption': corruption,\n",
    "        'severity': severity,\n",
    "        'acc': acc,\n",
    "        'ece': ece,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Create a new DataFrame for the new row\n",
    "new_row_df = pd.DataFrame(new_row_values).T\n",
    "# print(new_row_df)\n",
    "# Drop the 'base_model_' columns\n",
    "df = df.drop(columns=['base_model_acc', 'base_model_ece', 'base_model_precision', 'base_model_recall'])\n",
    "\n",
    "# Rename 'plumber_' columns\n",
    "df.columns = [col.replace('plumber_', '') for col in df.columns]\n",
    "\n",
    "# Add the new row to the top of the DataFrame\n",
    "df = pd.concat([new_row_df, df], ignore_index=True)\n",
    "\n",
    "# Save the dataframe\n",
    "# df.to_csv(f\"Distill:{save_data_name}-{model_name}.csv\", index=False)\n",
    "\n",
    "# Group by 'Model Type' and 'Feature Type' and calculate mean for specific columns\n",
    "grouped_df = df.groupby(['Model Type']).agg({\n",
    "    'acc': 'mean',\n",
    "    'ece': 'mean',\n",
    "    'precision': 'mean',\n",
    "    'recall': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "model_mapping = {\n",
    "    \"Task Model\": \"Task Model\",\n",
    "    \"Image (Prompt)\": \"plumber_img_prompt\",\n",
    "    \"Image (Project)\": \"plumber_img_proj\",\n",
    "    \"Image (Prompt + Project)\": \"plumber_img_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Cls Prompt)\": \"plumber_img_prompt_cls_LP\",\n",
    "    \"Image (Prompt) + Text (Project)\": \"plumber_text_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Prompt + Project)\": \"plumber_text_proj_img_prompt_cls_LP\",\n",
    "    \"Image (Project) + Text (Cls Prompt)\": \"plumber_img_proj_cls_LP\",\n",
    "    \"Image (Project) + Text (Project)\": \"plumber_img_text_proj\",\n",
    "    \"Image (Project) + Text (Prompt + Project)\": \"plumber_img_text_proj_cls_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Cls Prompt)\": \"plumber_img_proj_img_prompt_cls_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Project)\": \"plumber_img_text_proj_img_prompt\",\n",
    "    \"Image (Prompt + Project) + Text (Prompt + Project)\": \"plumber_img_text_proj_img_prompt_cls_LP\"\n",
    "}\n",
    "# Reverse the dictionary for replacement (value to key)\n",
    "reverse_mapping = {v: k for k, v in model_mapping.items()}\n",
    "\n",
    "# Replace the 'Model Type' in the DataFrame using the reversed mapping\n",
    "grouped_df['Model Type'] = grouped_df['Model Type'].map(reverse_mapping)\n",
    "\n",
    "# Create a custom sort order based on the order of keys in model_mapping\n",
    "sort_order = {k: i for i, k in enumerate(model_mapping.keys())}\n",
    "\n",
    "# Add a temporary sorting column based on the custom order\n",
    "grouped_df['Sort Order'] = grouped_df['Model Type'].map(sort_order)\n",
    "\n",
    "# Sort the DataFrame by this custom order and drop the temporary column\n",
    "grouped_df = grouped_df.sort_values(by='Sort Order').drop('Sort Order', axis=1)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(grouped_df)\n",
    "grouped_df.to_csv(f\"Distill:corr-{save_data_name}-{model_name}-grouped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the base folders\n",
    "model_types = [\n",
    "    \"plumber_img_prompt\", \"plumber_img_text_proj_img_prompt_cls_LP\",\n",
    "    \"plumber_img_proj\", \"plumber_img_prompt_cls_LP\", \n",
    "    \"plumber_text_proj_img_prompt\", \"plumber_img_proj_cls_LP\", \n",
    "    \"plumber_img_text_proj\", \"plumber_text_proj_img_prompt_cls_LP\", \n",
    "    \"plumber_img_proj_img_prompt\", \"plumber_img_text_proj_cls_LP\", \n",
    "    \"plumber_img_proj_img_prompt_cls_LP\", \"plumber_img_text_proj_img_prompt\"\n",
    "]\n",
    "corruption_folders = [\n",
    "    \"brightness\", \"contrast\", \"defocus_blur\", \"elastic_transform\", \"fog\",\n",
    "    \"frost\", \"gaussian_blur\", \"gaussian_noise\", \"glass_blur\", \"impulse_noise\",\n",
    "    \"jpeg_compression\", \"motion_blur\", \"pixelate\", \"saturate\", \"shot_noise\",\n",
    "    \"snow\", \"spatter\", \"speckle_noise\", \"zoom_blur\"\n",
    "]\n",
    "corruption_folders = [\"clipart\", \"infograph\", \"painting\", \"quickdraw\", \"real\", \"sketch\"]\n",
    "# corruption_folders = [f\"domainnet_{folder}_\" for folder in corruption_folders]\n",
    "\n",
    "# corruption_folders = [f\"cifar10-c_{folder}_4\" for folder in corruption_folders]\n",
    "\n",
    "corruption_folders = [\"\"]\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "save_data_name = \"cifar10\"\n",
    "model_name = \"SimpleCNN\"\n",
    "\n",
    "epoch = 29\n",
    "\n",
    "# Directory where these folders are located\n",
    "base_directory = f\"logs/{dataset}/{model_name}\"  # Replace with the actual path\n",
    "\n",
    "remaining_dir = f\"_clsEpoch_{epoch}_bs_128_lr_0.1_teT_2.0_sT_1.0_imgweight_1.0_txtweight_1.0_is_mlp_False/step_1/failure_detector\"\n",
    "\n",
    "# Function to extract metrics from a file\n",
    "def extract_metrics(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        data = {}\n",
    "        for line in lines:\n",
    "            if line.startswith(\"proj_features\") or line.startswith(\"classifier_features\") or line.startswith(\"clip_features\"):\n",
    "                parts = line.split()\n",
    "                data_type = parts[0]\n",
    "                metrics = {\n",
    "                    \"Accuracy\": float(parts[2].strip('%,')),\n",
    "                    \"Precision\": float(parts[4].strip('%,')),\n",
    "                    \"Recall\": float(parts[6].strip('%,')),\n",
    "                    \"F1 Score\": float(parts[9].strip('%'))\n",
    "                }\n",
    "                data[data_type] = metrics\n",
    "        return data\n",
    "\n",
    "def extract_metrics_from_json(file_path):\n",
    "    # classifier_features_metrics_single_svm\n",
    "    model_type = file_path.split(\"/\")[-1].split(\"_metrics\")[0]\n",
    "\n",
    "    # if model_type == \"plumber_img_prompt\" add update the model file_path to also include proj_features_metrics_single_svm and clip_features_metrics_single_svm\n",
    "    if model_type == \"plumber_img_prompt\":\n",
    "        file_paths = [file_path] + [file_path.replace(\"proj_features\", \"classifier_features\")] + [file_path.replace(\"proj_features\", \"clip_features\")]\n",
    "    else:\n",
    "        file_paths = [file_path]\n",
    "    \n",
    "    all_metrics = {}\n",
    "    for file_path in file_paths:\n",
    "        metrics = {}\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        metrics['task_model_acc'] = accuracy_score(data[\"gt_labels\"], data[\"task_pred\"])\n",
    "        metrics['estimated_acc'] = sum(data[\"correct_svm_pred\"]) / len(data[\"correct_svm_pred\"])\n",
    "        metrics['estimation_gap'] = data[\"estimation_gap\"]\n",
    "        metrics['failure_svm_accuracy'] = data[\"accu_failure_pred\"]\n",
    "        metrics['sucess_svm_accuracy'] = data[\"accu_success_pred\"]\n",
    "\n",
    "        all_metrics[model_type] = metrics\n",
    "\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_list = []\n",
    "# Iterate over the base folders and corruption folders\n",
    "for model_type in model_types:\n",
    "    path = os.path.join(base_directory, model_type)\n",
    "    for corruption_folder in corruption_folders:\n",
    "        corruption_path = os.path.join(path, remaining_dir, f\"{corruption_folder}\")\n",
    "        metrics_file = os.path.join(corruption_path, \"single_svm_metrics.txt\")\n",
    "        if os.path.exists(metrics_file):\n",
    "            metrics_data = extract_metrics(metrics_file)\n",
    "            print(metrics_data)\n",
    "            for key, values in metrics_data.items():\n",
    "                row = {\"Model Type\": model_type, \n",
    "                                \"Corruption\": corruption_folder,\n",
    "                                \"Feature Type\": key,\n",
    "                                **values}\n",
    "                \n",
    "                data_list.append(row)\n",
    "        else:\n",
    "            print(\"Metrics file not found for\", metrics_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Save the dataframe\n",
    "df.to_csv(f\"{save_data_name}-{model_name}.csv\", index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different dataframes for different corruption types\n",
    "df_corruptions = {}\n",
    "for corruption_folder in corruption_folders:\n",
    "    df_corruption = df[df[\"Corruption\"] == corruption_folder]\n",
    "    df_corruptions[corruption_folder] = df_corruption\n",
    "    print(df_corruption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Model Type' and 'Feature Type' and calculate mean for specific columns\n",
    "grouped_df = df.groupby(['Model Type', 'Feature Type']).agg({\n",
    "    'Accuracy': 'mean',\n",
    "    'Precision': 'mean',\n",
    "    'Recall': 'mean',\n",
    "    'F1 Score': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Display the new dataframe with mean values\n",
    "print(grouped_df)\n",
    "grouped_df.to_csv(f\"{save_data_name}-{model_name}-grouped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mapping = {\n",
    "    \"Image (Prompt)\": \"plumber_img_prompt\",\n",
    "    \"Image (Project)\": \"plumber_img_proj\",\n",
    "    \"Image (Prompt + Project)\": \"plumber_img_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Cls Prompt)\": \"plumber_img_prompt_cls_LP\",\n",
    "    \"Image (Prompt) + Text (Project)\": \"plumber_text_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Prompt + Project)\": \"plumber_text_proj_img_prompt_cls_LP\",\n",
    "    \"Image (Project) + Text (Cls Prompt)\": \"plumber_img_proj_cls_LP\",\n",
    "    \"Image (Project) + Text (Project)\": \"plumber_img_text_proj\",\n",
    "    \"Image (Project) + Text (Prompt + Project)\": \"plumber_img_text_proj_cls_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Cls Prompt)\": \"plumber_img_proj_img_prompt_cls_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Project)\": \"plumber_img_text_proj_img_prompt\",\n",
    "    \"Image (Prompt + Project) + Text (Prompt + Project)\": \"plumber_img_text_proj_img_prompt_cls_LP\"\n",
    "}\n",
    "# Reverse the dictionary for replacement (value to key)\n",
    "reverse_mapping = {v: k for k, v in model_mapping.items()}\n",
    "\n",
    "# Replace the 'Model Type' in the DataFrame using the reversed mapping\n",
    "grouped_df['Model Type'] = grouped_df['Model Type'].map(reverse_mapping)\n",
    "\n",
    "# Create a custom sort order based on the order of keys in model_mapping\n",
    "sort_order = {k: i for i, k in enumerate(model_mapping.keys())}\n",
    "\n",
    "# Add a temporary sorting column based on the custom order\n",
    "grouped_df['Sort Order'] = grouped_df['Model Type'].map(sort_order)\n",
    "\n",
    "# Sort the DataFrame by this custom order and drop the temporary column\n",
    "grouped_df = grouped_df.sort_values(by='Sort Order').drop('Sort Order', axis=1)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(grouped_df)\n",
    "# grouped_df.to_csv(\"Waterbirds-resnet18-grouped-sorted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(grouped_df[\"Accuracy\"])\n",
    "# list(grouped_df[\"Precision\"])\n",
    "list(grouped_df[\"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group each corruption type by 'Model Type' and 'Feature Type' and calculate mean for specific columns and remap the 'Model Type' using the reversed mapping\n",
    "# Also sort the DataFrame by the custom order\n",
    "\n",
    "# Create a custom sort order based on the order of keys in model_mapping\n",
    "sort_order = {k: i for i, k in enumerate(model_mapping.keys())}\n",
    "\n",
    "grouped_corruptions = {}\n",
    "for corruption_folder in corruption_folders:\n",
    "    df_corruption = df_corruptions[corruption_folder]\n",
    "    grouped_df_corruption = df_corruption.groupby(['Model Type', 'Feature Type']).agg({\n",
    "        'Accuracy': 'mean',\n",
    "        'Precision': 'mean',\n",
    "        'Recall': 'mean',\n",
    "        'F1 Score': 'mean'\n",
    "    }).reset_index()\n",
    "    grouped_df_corruption['Model Type'] = grouped_df_corruption['Model Type'].map(reverse_mapping)\n",
    "    grouped_df_corruption['Sort Order'] = grouped_df_corruption['Model Type'].map(sort_order)\n",
    "    grouped_df_corruption = grouped_df_corruption.sort_values(by='Sort Order').drop('Sort Order', axis=1)\n",
    "    grouped_corruptions[corruption_folder] = grouped_df_corruption\n",
    "    print(grouped_df_corruption)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a = [\"clipart\", \"infograph\", \"painting\", \"quickdraw\", \"real\", \"sketch\"]\n",
    "list(grouped_corruptions[corruption_folders[5]][\"Accuracy\"])\n",
    "list(grouped_corruptions[corruption_folders[5]][\"Precision\"])\n",
    "list(grouped_corruptions[corruption_folders[5]][\"Recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the base folders\n",
    "model_types = [\n",
    "    \"plumber_img_prompt\", \"plumber_img_text_proj_img_prompt_cls_LP\",\n",
    "    \"plumber_img_proj\", \"plumber_img_prompt_cls_LP\", \n",
    "    \"plumber_text_proj_img_prompt\", \"plumber_img_proj_cls_LP\", \n",
    "    \"plumber_img_text_proj\", \"plumber_text_proj_img_prompt_cls_LP\", \n",
    "    \"plumber_img_proj_img_prompt\", \"plumber_img_text_proj_cls_LP\", \n",
    "    \"plumber_img_proj_img_prompt_cls_LP\", \"plumber_img_text_proj_img_prompt\"\n",
    "]\n",
    "corruption_folders = [\n",
    "    \"brightness\", \"contrast\", \"defocus_blur\", \"elastic_transform\", \"fog\",\n",
    "    \"frost\", \"gaussian_blur\", \"gaussian_noise\", \"glass_blur\", \"impulse_noise\",\n",
    "    \"jpeg_compression\", \"motion_blur\", \"pixelate\", \"saturate\", \"shot_noise\",\n",
    "    \"snow\", \"spatter\", \"speckle_noise\", \"zoom_blur\"\n",
    "]\n",
    "corruption_folders = [f\"cifar10-c_{folder}_4\" for folder in corruption_folders]\n",
    "\n",
    "# corruption_folders = [\"clipart\", \"infograph\", \"painting\", \"quickdraw\", \"real\", \"sketch\"]\n",
    "# corruption_folders = [f\"{folder}\" for folder in corruption_folders]\n",
    "\n",
    "\n",
    "# corruption_folders = [\"\"]\n",
    "\n",
    "dataset = \"cifar10-limited\"\n",
    "save_data_name = \"cifar10c-limited\"\n",
    "model_name = \"resnet18\"\n",
    "\n",
    "epoch = 29\n",
    "\n",
    "# Directory where these folders are located\n",
    "base_directory = f\"logs/{dataset}/{model_name}\"  # Replace with the actual path\n",
    "\n",
    "remaining_dir = f\"_clsEpoch_{epoch}_bs_128_lr_0.1_teT_2.0_sT_1.0_imgweight_1.0_txtweight_1.0_is_mlp_False/step_1/failure_detector\"\n",
    "\n",
    "\n",
    "def extract_metrics_from_json(file_path, model_type):\n",
    "\n",
    "    # if model_type == \"plumber_img_prompt\" add update the model file_path to also include proj_features_metrics_single_svm and clip_features_metrics_single_svm\n",
    "    if model_type == \"plumber_img_prompt\":\n",
    "        file_paths = [file_path] + [file_path.replace(\"proj_features\", \"classifier_features\")] + [file_path.replace(\"proj_features\", \"clip_features\")]\n",
    "    else:\n",
    "        file_paths = [file_path]\n",
    "    \n",
    "    all_metrics = {}\n",
    "    for file_path in file_paths:\n",
    "        # Get the data type from the file path\n",
    "        data_type = file_path.split(\"/\")[-1].split(\"_metrics\")[0]\n",
    "        \n",
    "        metrics = {}\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        metrics['task_model_acc'] = accuracy_score(data[\"gt_labels\"], data[\"task_pred\"])\n",
    "        metrics['estimated_acc'] = sum(data[\"correct_svm_pred\"]) / len(data[\"correct_svm_pred\"])\n",
    "        metrics['estimation_gap'] = data[\"estimation_gap\"]\n",
    "\n",
    "        metrics['overall_svm_accuracy'] = data['class_report']['accuracy']\n",
    "\n",
    "        metrics['failure_svm_accuracy'] = data[\"accu_failure_pred\"]\n",
    "        metrics['sucess_svm_accuracy'] = data[\"accu_success_pred\"]\n",
    "\n",
    "        all_metrics[data_type] = metrics\n",
    "\n",
    "    return all_metrics\n",
    "\n",
    "data_list = []\n",
    "# Iterate over the base folders and corruption folders\n",
    "for model_type in model_types:\n",
    "    path = os.path.join(base_directory, model_type)\n",
    "    for corruption_folder in corruption_folders:\n",
    "        corruption_path = os.path.join(path, remaining_dir, f\"{corruption_folder}\")\n",
    "        metrics_file = os.path.join(corruption_path, \"proj_features_metrics_single_svm.json\")\n",
    "        if os.path.exists(metrics_file):\n",
    "            metrics_data = extract_metrics_from_json(metrics_file, model_type)\n",
    "            print(metrics_data)\n",
    "            for key, values in metrics_data.items():\n",
    "                row = {\"Model Type\": model_type, \n",
    "                                \"Corruption\": corruption_folder,\n",
    "                                \"Feature Type\": key,\n",
    "                                **values}\n",
    "                \n",
    "                data_list.append(row)\n",
    "        else:\n",
    "            print(\"Metrics file not found for\", metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Save the dataframe\n",
    "df.to_csv(f\"{save_data_name}-{model_name}.csv\", index=False)\n",
    "\n",
    "\n",
    "# Group by 'Model Type' and 'Feature Type' and calculate mean for specific columns\n",
    "grouped_df = df.groupby(['Model Type', 'Feature Type']).agg({\n",
    "    'task_model_acc': 'mean',\n",
    "    'estimated_acc': 'mean',\n",
    "    'estimation_gap': 'mean',\n",
    "    'overall_svm_accuracy': 'mean',\n",
    "    'failure_svm_accuracy': 'mean',\n",
    "    'sucess_svm_accuracy': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "model_mapping = {\n",
    "    \"Image (Prompt)\": \"plumber_img_prompt\",\n",
    "    \"Image (Project)\": \"plumber_img_proj\",\n",
    "    \"Image (Prompt + Project)\": \"plumber_img_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Cls Prompt)\": \"plumber_img_prompt_cls_LP\",\n",
    "    \"Image (Prompt) + Text (Project)\": \"plumber_text_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Prompt + Project)\": \"plumber_text_proj_img_prompt_cls_LP\",\n",
    "    \"Image (Project) + Text (Cls Prompt)\": \"plumber_img_proj_cls_LP\",\n",
    "    \"Image (Project) + Text (Project)\": \"plumber_img_text_proj\",\n",
    "    \"Image (Project) + Text (Prompt + Project)\": \"plumber_img_text_proj_cls_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Cls Prompt)\": \"plumber_img_proj_img_prompt_cls_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Project)\": \"plumber_img_text_proj_img_prompt\",\n",
    "    \"Image (Prompt + Project) + Text (Prompt + Project)\": \"plumber_img_text_proj_img_prompt_cls_LP\"\n",
    "}\n",
    "# Reverse the dictionary for replacement (value to key)\n",
    "reverse_mapping = {v: k for k, v in model_mapping.items()}\n",
    "\n",
    "# Replace the 'Model Type' in the DataFrame using the reversed mapping\n",
    "grouped_df['Model Type'] = grouped_df['Model Type'].map(reverse_mapping)\n",
    "\n",
    "# Create a custom sort order based on the order of keys in model_mapping\n",
    "sort_order = {k: i for i, k in enumerate(model_mapping.keys())}\n",
    "\n",
    "# Add a temporary sorting column based on the custom order\n",
    "grouped_df['Sort Order'] = grouped_df['Model Type'].map(sort_order)\n",
    "\n",
    "# Sort the DataFrame by this custom order and drop the temporary column\n",
    "grouped_df = grouped_df.sort_values(by='Sort Order').drop('Sort Order', axis=1)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(grouped_df)\n",
    "grouped_df.to_csv(f\"{save_data_name}-{model_name}-grouped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(grouped_df[\"Accuracy\"])\n",
    "# list(grouped_df[\"Precision\"])\n",
    "# list(grouped_df[\"Recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the base folders\n",
    "model_types = [\n",
    "    \"clip\", \"plumber_img_prompt\", \"plumber_img_text_proj_img_prompt_dataset_LP\",\n",
    "    \"plumber_img_proj\", \"plumber_img_prompt_dataset_LP\", \n",
    "    \"plumber_text_proj_img_prompt\", \"plumber_img_proj_dataset_LP\", \n",
    "    \"plumber_img_text_proj\", \"plumber_text_proj_img_prompt_dataset_LP\", \n",
    "    \"plumber_img_proj_img_prompt\", \"plumber_img_text_proj_dataset_LP\", \n",
    "    \"plumber_img_proj_img_prompt_dataset_LP\", \"plumber_img_text_proj_img_prompt\"\n",
    "]\n",
    "\n",
    "dataset = \"domainnet\"\n",
    "domain = \"real\"\n",
    "concept_set = \"domainnet_domain_concepts\"\n",
    "\n",
    "\n",
    "# Directory where these folders are located\n",
    "base_directory = f\"logs/{dataset}/shift_detection/{domain}\"  # Replace with the actual path\n",
    "\n",
    "remaining_dir = f\"_bs_256_lr_0.1_teT_2.0_sT_1.0_imgweight_1.0_txtweight_1.0_is_mlp_False/dissect/{concept_set}/concept_similarity\"\n",
    "\n",
    "def extract_metrics_from_json(file_path, model_type):\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "       \n",
    "    return data\n",
    "\n",
    "data_list = []\n",
    "# Iterate over the base folders and corruption folders\n",
    "for model_type in model_types:\n",
    "    path = os.path.join(base_directory, model_type, remaining_dir)\n",
    "    metrics_file = os.path.join(path, \"concept_similarity.json\")\n",
    "    if os.path.exists(metrics_file):\n",
    "        metrics_data = extract_metrics_from_json(metrics_file, model_type)\n",
    "        \n",
    "        # add model type to the metrics data\n",
    "        metrics_data[\"Model Type\"] = model_type\n",
    "        print(metrics_data)\n",
    "            \n",
    "        data_list.append(metrics_data)\n",
    "    else:\n",
    "        print(\"Metrics file not found for\", metrics_file)\n",
    "        data_list.append({\"Model Type\": model_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# # Save the dataframe\n",
    "# df.to_csv(f\"{save_data_name}-{model_name}.csv\", index=False)\n",
    "\n",
    "\n",
    "model_mapping = {\n",
    "    \"clip\": \"clip\",\n",
    "    \"Image (Prompt)\": \"plumber_img_prompt\",\n",
    "    \"Image (Project)\": \"plumber_img_proj\",\n",
    "    \"Image (Prompt + Project)\": \"plumber_img_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Dataset Prompt)\": \"plumber_img_prompt_dataset_LP\",\n",
    "    \"Image (Prompt) + Text (Project)\": \"plumber_text_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Dataset Prompt + Project)\": \"plumber_text_proj_img_prompt_dataset_LP\",\n",
    "    \"Image (Project) + Text (Dataset Prompt)\": \"plumber_img_proj_dataset_LP\",\n",
    "    \"Image (Project) + Text (Project)\": \"plumber_img_text_proj\",\n",
    "    \"Image (Project) + Text (Dataset Prompt + Project)\": \"plumber_img_text_proj_dataset_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Dataset Prompt)\": \"plumber_img_proj_img_prompt_dataset_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Project)\": \"plumber_img_text_proj_img_prompt\",\n",
    "    \"Image (Prompt + Project) + Text (Dataset Prompt + Project)\": \"plumber_img_text_proj_img_prompt_dataset_LP\"\n",
    "}\n",
    "# Reverse the dictionary for replacement (value to key)\n",
    "reverse_mapping = {v: k for k, v in model_mapping.items()}\n",
    "\n",
    "# Replace the 'Model Type' in the DataFrame using the reversed mapping\n",
    "df['Model Type'] = df['Model Type'].map(reverse_mapping)\n",
    "\n",
    "# Create a custom sort order based on the order of keys in model_mapping\n",
    "sort_order = {k: i for i, k in enumerate(model_mapping.keys())}\n",
    "\n",
    "# Add a temporary sorting column based on the custom order\n",
    "df['Sort Order'] = df['Model Type'].map(sort_order)\n",
    "\n",
    "# Sort the DataFrame by this custom order and drop the temporary column\n",
    "df = df.sort_values(by='Sort Order').drop('Sort Order', axis=1)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(df)\n",
    "df.to_csv(f\"SD:{dataset}-{domain}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeroshot Abilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the base folders\n",
    "model_types = [\n",
    "    \"clip\", \"plumber_img_prompt\", \"plumber_img_text_proj_img_prompt_dataset_LP\",\n",
    "    \"plumber_img_proj\", \"plumber_dataset_LP\", \"plumber_text_proj\",\n",
    "    \"plumber_text_proj_dataset_LP\", \"plumber_img_prompt_dataset_LP\", \n",
    "    \"plumber_text_proj_img_prompt\", \"plumber_img_proj_dataset_LP\", \n",
    "    \"plumber_img_text_proj\", \"plumber_text_proj_img_prompt_dataset_LP\", \n",
    "    \"plumber_img_proj_img_prompt\", \"plumber_img_text_proj_dataset_LP\", \n",
    "    \"plumber_img_proj_img_prompt_dataset_LP\", \"plumber_img_text_proj_img_prompt\"\n",
    "]\n",
    "zsl_datasets=[\"cifar10\", \"cifar100\", \"gtsrb\", \"svhn\", \"dtd\", \"oxfordpets\",  \"food101\", \"eurosat\", \"sun397\", \"ucf101\", \"stanfordcars\", \"flowers102\"]\n",
    "zsl_datasets=[\"cifar10\", \"cifar100\"]\n",
    "dataset = \"domainnet\"\n",
    "domain = \"real\"\n",
    "\n",
    "\n",
    "# Directory where these folders are located\n",
    "base_directory = f\"logs/{dataset}/shift_detection/{domain}\"  # Replace with the actual path\n",
    "\n",
    "remaining_dir = f\"_bs_256_lr_0.1_teT_2.0_sT_1.0_imgweight_1.0_txtweight_1.0_is_mlp_False/logs\"\n",
    "\n",
    "\n",
    "data_list = []\n",
    "# Iterate over the base folders and corruption folders\n",
    "for model_type in model_types:\n",
    "    path = os.path.join(base_directory, model_type, remaining_dir)\n",
    "    zsl_results = {\n",
    "        \"Model Type\": model_type,\n",
    "    }\n",
    "    for zsl_dataset in zsl_datasets:\n",
    "        # Read the csv file and extract the test accuracy\n",
    "        csv_file = os.path.join(path, f\"{zsl_dataset}results.csv\")\n",
    "        if os.path.exists(csv_file):\n",
    "            df = pd.read_csv(csv_file)\n",
    "            test_acc = df.iloc[-1][\"Test Acc\"]\n",
    "        else:\n",
    "            print(\"Metrics file not found for\", csv_file)\n",
    "            test_acc = None\n",
    "        zsl_results[zsl_dataset] = test_acc\n",
    "    \n",
    "    data_list.append(zsl_results)\n",
    "\n",
    "    \n",
    "\n",
    "    # if os.path.exists(metrics_file):\n",
    "    #     metrics_data = extract_metrics_from_json(metrics_file, model_type)\n",
    "        \n",
    "    #     # add model type to the metrics data\n",
    "    #     metrics_data[\"Model Type\"] = model_type\n",
    "    #     print(metrics_data)\n",
    "            \n",
    "    #     data_list.append(metrics_data)\n",
    "    # else:\n",
    "    #     print(\"Metrics file not found for\", metrics_file)\n",
    "    #     data_list.append({\"Model Type\": model_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "print(df)\n",
    "# # Save the dataframe\n",
    "# df.to_csv(f\"{save_data_name}-{model_name}.csv\", index=False)\n",
    "\n",
    "\n",
    "model_mapping = {\n",
    "    \"clip\": \"clip\",\n",
    "    \"Image (Prompt)\": \"plumber_img_prompt\",\n",
    "    \"Image (Project)\": \"plumber_img_proj\",\n",
    "    \"Image (Prompt + Project)\": \"plumber_img_proj_img_prompt\",\n",
    "    \"Text (Dataset Prompt)\": \"plumber_dataset_LP\",\n",
    "    \"Text (Project)\": \"plumber_text_proj\",\n",
    "    \"Text (Dataset Prompt + Project)\": \"plumber_text_proj_dataset_LP\",\n",
    "    \"Image (Prompt) + Text (Dataset Prompt)\": \"plumber_img_prompt_dataset_LP\",\n",
    "    \"Image (Prompt) + Text (Project)\": \"plumber_text_proj_img_prompt\",\n",
    "    \"Image (Prompt) + Text (Dataset Prompt + Project)\": \"plumber_text_proj_img_prompt_dataset_LP\",\n",
    "    \"Image (Project) + Text (Dataset Prompt)\": \"plumber_img_proj_dataset_LP\",\n",
    "    \"Image (Project) + Text (Project)\": \"plumber_img_text_proj\",\n",
    "    \"Image (Project) + Text (Dataset Prompt + Project)\": \"plumber_img_text_proj_dataset_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Dataset Prompt)\": \"plumber_img_proj_img_prompt_dataset_LP\",\n",
    "    \"Image (Prompt + Project) + Text (Project)\": \"plumber_img_text_proj_img_prompt\",\n",
    "    \"Image (Prompt + Project) + Text (Dataset Prompt + Project)\": \"plumber_img_text_proj_img_prompt_dataset_LP\"\n",
    "}\n",
    "# Reverse the dictionary for replacement (value to key)\n",
    "reverse_mapping = {v: k for k, v in model_mapping.items()}\n",
    "\n",
    "# Replace the 'Model Type' in the DataFrame using the reversed mapping\n",
    "df['Model Type'] = df['Model Type'].map(reverse_mapping)\n",
    "\n",
    "# Create a custom sort order based on the order of keys in model_mapping\n",
    "sort_order = {k: i for i, k in enumerate(model_mapping.keys())}\n",
    "\n",
    "# Add a temporary sorting column based on the custom order\n",
    "df['Sort Order'] = df['Model Type'].map(sort_order)\n",
    "\n",
    "# Sort the DataFrame by this custom order and drop the temporary column\n",
    "df = df.sort_values(by='Sort Order').drop('Sort Order', axis=1)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(df)\n",
    "df.to_csv(f\"ZSL:{dataset}-{domain}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP(\n",
      "  (visual): VisionTransformer(\n",
      "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
      "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): Sequential(\n",
      "        (0): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): ResidualAttentionBlock(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (resblocks): Sequential(\n",
      "      (0): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): ResidualAttentionBlock(\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (gelu): QuickGELU()\n",
      "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (token_embedding): Embedding(49408, 512)\n",
      "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=\"cpu\")\n",
    "\n",
    "print(clip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "checkpoint = torch.load('logs/cifar10/SimpleCNN/masked_img_encoder/_clsEpoch_29_bs_256_lr_0.1_teT_2.0_sT_1.0_imgweight_1.0_txtweight_1.0_is_mlp_False/step_1/projector_weights_16.pth',\n",
    "                        map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(82.6875, dtype=torch.float16)\n",
      "tensor(-82.6609)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(50,1,768)\n",
    "\n",
    "b = checkpoint['masked_visual_encoder'][\"masks.10\"]\n",
    "\n",
    "print(torch.sum(a), torch.sum(b))\n",
    "print(torch.sum(a-b))\n",
    "\n",
    "torch.allclose(a[1,:,:], b.float()[1,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0138, -0.0089, -0.0053,  ..., -0.0090,  0.0002,  0.0078]],\n",
       "\n",
       "        [[ 0.0140, -0.0045, -0.0007,  ...,  0.0036, -0.0054, -0.0057]],\n",
       "\n",
       "        [[ 0.0133,  0.0040, -0.0057,  ..., -0.0080,  0.0598,  0.0060]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0039,  0.0145, -0.0017,  ...,  0.0040,  0.0025, -0.0067]],\n",
       "\n",
       "        [[ 0.0086,  0.0067,  0.0020,  ..., -0.0064,  0.0070,  0.0064]],\n",
       "\n",
       "        [[ 0.0051, -0.0140, -0.0004,  ...,  0.0001,  0.0077,  0.0008]]],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
